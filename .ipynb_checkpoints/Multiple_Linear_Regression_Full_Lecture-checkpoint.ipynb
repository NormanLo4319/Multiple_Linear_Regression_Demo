{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "handed-wisdom",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "In this demo, we are going to review and practice using the multiple linear regression to extract some meaningful insight from various data sets.\n",
    "\n",
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Multiple-Linear-Regression\" data-toc-modified-id=\"Multiple-Linear-Regression-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Multiple Linear Regression</a></span></li><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Regression-with-Multiple-Predictors\" data-toc-modified-id=\"Regression-with-Multiple-Predictors-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Regression with Multiple Predictors</a></span><ul class=\"toc-item\"><li><span><a href=\"#Expanding-Simple-Linear-Regression\" data-toc-modified-id=\"Expanding-Simple-Linear-Regression-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Expanding Simple Linear Regression</a></span></li><li><span><a href=\"#Closed-form-Solution\" data-toc-modified-id=\"Closed-form-Solution-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Closed-form Solution</a></span></li></ul></li><li><span><a href=\"#Confounding-Variables\" data-toc-modified-id=\"Confounding-Variables-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Confounding Variables</a></span></li><li><span><a href=\"#Dealing-with-Categorical-Variables\" data-toc-modified-id=\"Dealing-with-Categorical-Variables-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Dealing with Categorical Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dummying\" data-toc-modified-id=\"Dummying-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Dummying</a></span></li></ul></li><li><span><a href=\"#Multiple-Regression-in-statsmodels\" data-toc-modified-id=\"Multiple-Regression-in-statsmodels-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Multiple Regression in <code>statsmodels</code></a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Diamonds-Dataset\" data-toc-modified-id=\"Diamonds-Dataset-6.0.1\"><span class=\"toc-item-num\">6.0.1&nbsp;&nbsp;</span>Diamonds Dataset</a></span></li><li><span><a href=\"#Check-distribution-of-target\" data-toc-modified-id=\"Check-distribution-of-target-6.0.2\"><span class=\"toc-item-num\">6.0.2&nbsp;&nbsp;</span>Check distribution of target</a></span></li><li><span><a href=\"#Build-model-with-log-scaled-target\" data-toc-modified-id=\"Build-model-with-log-scaled-target-6.0.3\"><span class=\"toc-item-num\">6.0.3&nbsp;&nbsp;</span>Build model with log-scaled target</a></span></li></ul></li></ul></li><li><span><a href=\"#Putting-it-in-Practice:-Wine-Dataset-üç∑\" data-toc-modified-id=\"Putting-it-in-Practice:-Wine-Dataset-üç∑-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Putting it in Practice: Wine Dataset üç∑</a></span><ul class=\"toc-item\"><li><span><a href=\"#üß†-Knowledge-Check\" data-toc-modified-id=\"üß†-Knowledge-Check-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>üß† <strong>Knowledge Check</strong></a></span></li><li><span><a href=\"#Running-the-Regression\" data-toc-modified-id=\"Running-the-Regression-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Running the Regression</a></span></li></ul></li><li><span><a href=\"#Scaling---The-Missing-&amp;-Helpful-Step\" data-toc-modified-id=\"Scaling---The-Missing-&amp;-Helpful-Step-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Scaling - The Missing &amp; Helpful Step</a></span><ul class=\"toc-item\"><li><span><a href=\"#What's-Going-on-Here?\" data-toc-modified-id=\"What's-Going-on-Here?-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>What's Going on Here?</a></span></li><li><span><a href=\"#A-Solution:-Standard-Scaling\" data-toc-modified-id=\"A-Solution:-Standard-Scaling-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>A Solution: Standard Scaling</a></span></li><li><span><a href=\"#Redoing-with-Standard-Scaling\" data-toc-modified-id=\"Redoing-with-Standard-Scaling-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Redoing with Standard Scaling</a></span></li><li><span><a href=\"#üß†-Knowledge-Check\" data-toc-modified-id=\"üß†-Knowledge-Check-8.4\"><span class=\"toc-item-num\">8.4&nbsp;&nbsp;</span>üß† <strong>Knowledge Check</strong></a></span></li><li><span><a href=\"#üß†-Knowledge-Check\" data-toc-modified-id=\"üß†-Knowledge-Check-8.5\"><span class=\"toc-item-num\">8.5&nbsp;&nbsp;</span>üß† <strong>Knowledge Check</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Follow-Up\" data-toc-modified-id=\"Follow-Up-8.5.1\"><span class=\"toc-item-num\">8.5.1&nbsp;&nbsp;</span>Follow-Up</a></span></li></ul></li></ul></li><li><span><a href=\"#Multiple-Regression-in-Scikit-Learn\" data-toc-modified-id=\"Multiple-Regression-in-Scikit-Learn-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Multiple Regression in Scikit-Learn</a></span><ul class=\"toc-item\"><li><span><a href=\"#Scale-the-Data\" data-toc-modified-id=\"Scale-the-Data-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Scale the Data</a></span></li><li><span><a href=\"#Fit-the-Model\" data-toc-modified-id=\"Fit-the-Model-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Fit the Model</a></span></li><li><span><a href=\"#Evaluate-Performance\" data-toc-modified-id=\"Evaluate-Performance-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>Evaluate Performance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Observing-Residuals\" data-toc-modified-id=\"Observing-Residuals-9.3.1\"><span class=\"toc-item-num\">9.3.1&nbsp;&nbsp;</span>Observing Residuals</a></span></li><li><span><a href=\"#Sklearn-Metrics\" data-toc-modified-id=\"Sklearn-Metrics-9.3.2\"><span class=\"toc-item-num\">9.3.2&nbsp;&nbsp;</span>Sklearn Metrics</a></span></li><li><span><a href=\"#More-in-Exploring-of-the-Predictions\" data-toc-modified-id=\"More-in-Exploring-of-the-Predictions-9.3.3\"><span class=\"toc-item-num\">9.3.3&nbsp;&nbsp;</span>More in Exploring of the Predictions</a></span></li></ul></li></ul></li><li><span><a href=\"#Level-Up:-Deeper-Evaluation-of-Wine-Data-Predictions\" data-toc-modified-id=\"Level-Up:-Deeper-Evaluation-of-Wine-Data-Predictions-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Level Up: Deeper Evaluation of Wine Data Predictions</a></span></li><li><span><a href=\"#Level-Up:-Regression-with-Categorical-Features-with-the-Comma-Dataset\" data-toc-modified-id=\"Level-Up:-Regression-with-Categorical-Features-with-the-Comma-Dataset-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Level Up: Regression with Categorical Features with the Comma Dataset</a></span></li></ul></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-basement",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-window",
   "metadata": {},
   "source": [
    "![mlr](https://miro.medium.com/max/1280/1*lJKFo3yyZaFIx4ET1dLmlg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-defensive",
   "metadata": {},
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-relations",
   "metadata": {},
   "source": [
    "- Use the one-hot strategy to encode categorical variables\n",
    "- Conduct linear regressions in `statsmodels`\n",
    "- Use standard scaling for linear regression for better  interpretation\n",
    "- Conduct linear regressions in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-knitting",
   "metadata": {},
   "source": [
    "# Regression with Multiple Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-purchase",
   "metadata": {},
   "source": [
    "> It's all a bunch of dials\n",
    "\n",
    "<img width='450px' src='img/dials.png'/>\n",
    "\n",
    "The main idea here is pretty simple. Whereas, in simple linear regression we took our dependent variable to be a function only of a single independent variable, here we'll be taking the dependent variable to be a function of multiple independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-temple",
   "metadata": {},
   "source": [
    "## Expanding Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-coordination",
   "metadata": {},
   "source": [
    "Our regression equation, then, instead of looking like $\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 x$, will now look like:\n",
    "\n",
    "$$\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1x_1 + ... + \\hat{\\beta}_nx_n$$\n",
    "\n",
    "Remember that the hats ( $\\hat{}$ ) indicate parameters that are estimated.\n",
    "\n",
    "Is this still a best-fit *line*? Well, no. What does the graph of, say, z = x + y look like? [Here's](https://academo.org/demos/3d-surface-plotter/) a 3d-plotter. (Of course, once we get x's with subscripts beyond 2 it's going to be very hard to visualize. But in practice linear regressions can make use of dozens or even of hundreds of independent variables!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-device",
   "metadata": {},
   "source": [
    "## Closed-form Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-color",
   "metadata": {},
   "source": [
    "Is it possible to calculate the $\\beta$s by hand? Yes, a multiple regression problem still has a closed-form solution.\n",
    "\n",
    "In a word, for a multiple linear regression problem where $X$ is the matrix of independent variable values and $y$ is the vector of dependent variable values, the vector of optimizing regression coefficients $\\vec{b}$ is given by:\n",
    "\n",
    "$$\\vec{b} = (X^TX)^{-1}X^Ty$$\n",
    "\n",
    "We'll focus more directly on matrix mathematics later in the course, so don't worry if this equation is opaque to you. See [here](https://stattrek.com/multiple-regression/regression-coefficients.aspx) for a nice explanation and example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-python",
   "metadata": {},
   "source": [
    "# Confounding Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-stadium",
   "metadata": {},
   "source": [
    "Suppose I have a simple linear regression that models the growth of corn plants as a function of the temperature of the ambient air. And suppose there is a noticeable positive correlation between temperature and plant height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-allen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'corn' data set\n",
    "corn = pd.read_csv('data/corn.csv', \n",
    "                   usecols=['temp', 'humid', 'height'])\n",
    "\n",
    "# Extract the first 5 rows of the data\n",
    "corn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot corn height against temperature with regression line\n",
    "sns.lmplot(data=corn, x='temp', y='height')\n",
    "plt.xlabel('Temperature ($\\degree$ F)')\n",
    "plt.ylabel('Height (cm)')\n",
    "plt.title('Corn plant height as a function of temperature');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-replication",
   "metadata": {},
   "source": [
    "It seems that higher temperatures lead to taller corn plants. But it's hard to know for sure. One **confounding variable** might be *humidity*. If we haven't controlled for humidity, then it's difficult to draw conclusions.\n",
    "\n",
    "One solution is to use **both features** in a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot corn height against humidity with regression line\n",
    "sns.lmplot(data=corn, x='humid', y='height')\n",
    "plt.xlabel('Humidity (%)')\n",
    "plt.ylabel('Height (cm)')\n",
    "plt.title('Corn plant height as a function of humidity');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-chocolate",
   "metadata": {},
   "source": [
    "When we are using two independent variables in multiple linear regression model, we are fitting a hyperplane / surface to the data in a 3 dimensional space. Here is the visualization of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 3D figure for plotting the data and surface\n",
    "ax = plt.figure(figsize=(8, 6)).add_subplot(111, projection='3d')\n",
    "ax.scatter(corn['temp'], corn['humid'], corn['height'],\n",
    "           depthshade=True, s=40, color='#ff0000')\n",
    "# create x,y\n",
    "xx, yy = np.meshgrid(corn['temp'], corn['humid'])\n",
    "\n",
    "# calculate corresponding z\n",
    "z = 4.3825 * xx + 2.4693 * yy - 255.5434\n",
    "\n",
    "# plot the surface\n",
    "ax.plot_surface(xx, yy, z, alpha=0.01, color='#00ff00')\n",
    "\n",
    "ax.view_init(30, azim=240)\n",
    "ax.set_xlabel('Temperature ($\\degree$ F)')\n",
    "ax.set_ylabel('Humidity (%)')\n",
    "ax.set_zlabel('Height (cm)')\n",
    "plt.title('Corn plant height as a function of temperature and humidity');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ultimate-strain",
   "metadata": {},
   "source": [
    "One risk we run when adding more predictors to a model is that their correlations with the target may be nearly *collinear* with each other. This can make it difficult to determine which predictor is doing the heavy lifting. We shall explore this theme of **multicollinearity** in more depth in due course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-clone",
   "metadata": {},
   "source": [
    "# Dealing with Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-engagement",
   "metadata": {},
   "source": [
    "One issue we'd like to resolve is what to do with categorical variables, i.e. variables that represent categories rather than continua. In a Pandas DataFrame, these columns may well have strings or objects for values, but they need not. A certain heart-disease dataset from Kaggle, for example, has a target variable that takes values 0-4, each representing a different stage of heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-alfred",
   "metadata": {},
   "source": [
    "## Dummying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-cutting",
   "metadata": {},
   "source": [
    "One effective way of dealing with categorical variables is to dummy them out. What this involves is making a new column for *each categorical value (level) in the column we're dummying out*.\n",
    "\n",
    "These new columns will be filled only with 0's and 1's, a 1 representing the presence of the relevant categorical value (level).\n",
    "\n",
    "Example:\n",
    "\n",
    "| User_ID | Color |\n",
    "| :---: | :---: |\n",
    "| AD154 | Blue |\n",
    "| CE439 | Green |\n",
    "| TS990 | Blue |\n",
    "| DE468 | Red |\n",
    "\n",
    "Transform into dummy columns:\n",
    "\n",
    "| User_ID | Blue | Green | Red |\n",
    "| :---: | :---: | :---: | :---: |\n",
    "| AD154 |  1 | 0 | 0 |\n",
    "| CE439 |  0 | 1 | 0 |\n",
    "| TS990 |  1 | 0 | 0 |\n",
    "| DE468 |  0 | 0 | 1 |\n",
    "\n",
    "**Note**: When using categorical variable in a regression model, we include k - 1 level(s) and leave one out as the **reference level**. In the previous example, we can include the columns 'Blue' and 'Green' in the model and leave the 'Red' column out. The reference level can be any column between the three levels.\n",
    "\n",
    "Let's look at a simple example with the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'comma-survey' data set\n",
    "comma_use = pd.read_csv('data/comma-survey.csv')\n",
    "\n",
    "# Extract the head of the data set\n",
    "comma_use.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-neutral",
   "metadata": {},
   "source": [
    "For more on this dataset see [here](https://fivethirtyeight.com/features/elitist-superfluous-or-popular-we-polled-americans-on-the-oxford-comma/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-harmony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the count of each unique value in column 'In your opinion, which sentence is more gramatically correct?'\n",
    "comma_use['In your opinion, which sentence is more gramatically correct?'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-corpus",
   "metadata": {},
   "source": [
    "Cleaning the data before creating the dummy variables / columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dimension of the data frame\n",
    "comma_use.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-barbados",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any missing values in the data frame\n",
    "comma_use.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "comma_use.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-gallery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dimension again after dropping the rows with missing values\n",
    "comma_use.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executive-redhead",
   "metadata": {},
   "source": [
    "Using **sklearn**'s OneHotEncoder to create the dummy columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoder that creates K - 1 dummy columns\n",
    "ohe = OneHotEncoder(drop = 'first')\n",
    "\n",
    "# Transform all categorical variables into dummy columns except 'RespondentID'\n",
    "comma_trans = ohe.fit_transform(comma_use.drop('RespondentID', axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-works",
   "metadata": {},
   "source": [
    "Could we have used ```pd.get_dummies()``` instead?\n",
    "\n",
    "Well, yes. And in fact ```get_dummies()``` is in some ways easier; for one thing, it's built right into Pandas. But there are drawbacks with it as well. The main advantage of the `sklearn` tool is that it stores information about the columns and creates a persistent function that can be used on future data of the same form. See [this page](https://stackoverflow.com/questions/36631163/pandas-get-dummies-vs-sklearns-onehotencoder-what-are-the-pros-and-cons) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Pandas get_dummies() function to create dummy columns\n",
    "pd.get_dummies(comma_use.drop('RespondentID', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-bicycle",
   "metadata": {},
   "source": [
    "So what did the encoder do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the transformed object\n",
    "comma_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numpy matrix object using the todense() method\n",
    "comma_trans.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the feature names of the transformed matrix\n",
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the matrix and feature names into a Pandas data frame\n",
    "comma_df = pd.DataFrame(comma_trans.todense(), columns=ohe.get_feature_names())\n",
    "comma_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-estonia",
   "metadata": {},
   "source": [
    "# Multiple Regression in `statsmodels`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-cinema",
   "metadata": {},
   "source": [
    "Let's build a multiple regression with `statsmodels`. Let's start with a toy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import numpy as np\n",
    "from scipy import stats as stats\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a 5 random variables\n",
    "centers = np.arange(1, 6)\n",
    "preds = np.array([stats.norm(loc=center, scale=3).rvs(200) for center in centers]).T\n",
    "preds_df = pd.DataFrame(preds, columns=[f'var{center}' for center in centers])\n",
    "\n",
    "# Set the target values depends on the 5 random variables\n",
    "target = preds_df['var1'] + 2*preds_df['var2'] + 3*preds_df['var3']\\\n",
    "    + 4*preds_df['var4'] + 5*preds_df['var5']\n",
    "target_df = pd.DataFrame(target, columns=['target'])\n",
    "\n",
    "# Combine the target column with the 5 random variables columns into a data frame\n",
    "df = pd.concat([preds_df, target_df], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target 'y' and predictors 'X'\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OLS model and fit the simulate data\n",
    "model = sm.OLS(endog = y, exog = X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model summary table\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-satisfaction",
   "metadata": {},
   "source": [
    "### Diamonds Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the 'diamonds' data set from seaborn module\n",
    "data = sns.load_dataset('diamonds').drop(['cut', 'color', 'clarity'], axis = 1)\n",
    "\n",
    "# Extract the head of the data set\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target and predictors for regression\n",
    "X, y = data.drop('price', axis=1), data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OLS model and fit the data\n",
    "model2 = sm.OLS(y, X).fit()\n",
    "\n",
    "# Print the model summary table\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model with some standard visualizations\n",
    "sm.graphics.plot_regress_exog(model2, 'carat', fig=plt.figure(figsize=(12, 8)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-marathon",
   "metadata": {},
   "source": [
    "### Check distribution of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the target variable 'Price'\n",
    "y.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-daniel",
   "metadata": {},
   "source": [
    "The distribution of the target variable, price of the diamond, is obviously **skewed to the right**. This could affect the model performance and prediction result. One way to solve this problem is to scale the value by taking the log of the price column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the target by taking log of each price value\n",
    "y_scld = np.log(y)\n",
    "\n",
    "# Check the distribution of the scaled target \n",
    "y_scld.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-position",
   "metadata": {},
   "source": [
    "### Build model with log-scaled target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the OLS model again with the log-scaled target\n",
    "model3 = sm.OLS(y_scld, X).fit()\n",
    "\n",
    "# Print the model summary table\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model with the standard visualization again\n",
    "sm.graphics.plot_regress_exog(model3, 'carat', fig=plt.figure(figsize=(12, 8)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-rocket",
   "metadata": {},
   "source": [
    "**Remember that $R^2$ can be negative!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependency\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two examples to demonstrate the negative R^2\n",
    "bad_pred = np.mean(y) * np.ones(len(y))\n",
    "worse_pred = (np.mean(y) + 1000) * np.ones(len(y))\n",
    "\n",
    "# Print the R^2 values for each example\n",
    "print(metrics.r2_score(y, bad_pred))\n",
    "print(metrics.r2_score(y, worse_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-cinema",
   "metadata": {},
   "source": [
    "# Putting it in Practice: Wine Dataset üç∑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-yugoslavia",
   "metadata": {},
   "source": [
    "This dataset includes measurable attributes of different wines as well as their rated quality. We are going to fit the data with multiple linear regression model using ```statsmodel``` library.\n",
    "\n",
    "General Workflow:\n",
    "1. Checking the data set to make sure it is ready to fit into the model.\n",
    "2. Clean or manupulate the data if needed.\n",
    "3. Create the predictors (independent) and target (dependent) matrices\n",
    "4. Add the constant column to the predictor matrix\n",
    "5. Fit the data using ```sm.OLS()```\n",
    "6. Print the regression summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "verified-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suitable-thickness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>red_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  red_wine  \n",
       "0      9.4        5         1  \n",
       "1      9.8        5         1  \n",
       "2      9.8        5         1  \n",
       "3      9.8        6         1  \n",
       "4      9.4        5         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the 'wine' data set\n",
    "wine = pd.read_csv('data/wine.csv')\n",
    "\n",
    "# Extract the head of the data set\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "municipal-restoration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         6497 non-null   float64\n",
      " 1   volatile acidity      6497 non-null   float64\n",
      " 2   citric acid           6497 non-null   float64\n",
      " 3   residual sugar        6497 non-null   float64\n",
      " 4   chlorides             6497 non-null   float64\n",
      " 5   free sulfur dioxide   6497 non-null   float64\n",
      " 6   total sulfur dioxide  6497 non-null   float64\n",
      " 7   density               6497 non-null   float64\n",
      " 8   pH                    6497 non-null   float64\n",
      " 9   sulphates             6497 non-null   float64\n",
      " 10  alcohol               6497 non-null   float64\n",
      " 11  quality               6497 non-null   int64  \n",
      " 12  red_wine              6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 660.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Check the data set info\n",
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respiratory-airline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>red_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "      <td>6497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.215307</td>\n",
       "      <td>0.339666</td>\n",
       "      <td>0.318633</td>\n",
       "      <td>5.443235</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>30.525319</td>\n",
       "      <td>115.744574</td>\n",
       "      <td>0.994697</td>\n",
       "      <td>3.218501</td>\n",
       "      <td>0.531268</td>\n",
       "      <td>10.491801</td>\n",
       "      <td>5.818378</td>\n",
       "      <td>0.246114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.296434</td>\n",
       "      <td>0.164636</td>\n",
       "      <td>0.145318</td>\n",
       "      <td>4.757804</td>\n",
       "      <td>0.035034</td>\n",
       "      <td>17.749400</td>\n",
       "      <td>56.521855</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.160787</td>\n",
       "      <td>0.148806</td>\n",
       "      <td>1.192712</td>\n",
       "      <td>0.873255</td>\n",
       "      <td>0.430779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.987110</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.992340</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>0.994890</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.996990</td>\n",
       "      <td>3.320000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>11.300000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>65.800000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>440.000000</td>\n",
       "      <td>1.038980</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    6497.000000       6497.000000  6497.000000     6497.000000   \n",
       "mean        7.215307          0.339666     0.318633        5.443235   \n",
       "std         1.296434          0.164636     0.145318        4.757804   \n",
       "min         3.800000          0.080000     0.000000        0.600000   \n",
       "25%         6.400000          0.230000     0.250000        1.800000   \n",
       "50%         7.000000          0.290000     0.310000        3.000000   \n",
       "75%         7.700000          0.400000     0.390000        8.100000   \n",
       "max        15.900000          1.580000     1.660000       65.800000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  6497.000000          6497.000000           6497.000000  6497.000000   \n",
       "mean      0.056034            30.525319            115.744574     0.994697   \n",
       "std       0.035034            17.749400             56.521855     0.002999   \n",
       "min       0.009000             1.000000              6.000000     0.987110   \n",
       "25%       0.038000            17.000000             77.000000     0.992340   \n",
       "50%       0.047000            29.000000            118.000000     0.994890   \n",
       "75%       0.065000            41.000000            156.000000     0.996990   \n",
       "max       0.611000           289.000000            440.000000     1.038980   \n",
       "\n",
       "                pH    sulphates      alcohol      quality     red_wine  \n",
       "count  6497.000000  6497.000000  6497.000000  6497.000000  6497.000000  \n",
       "mean      3.218501     0.531268    10.491801     5.818378     0.246114  \n",
       "std       0.160787     0.148806     1.192712     0.873255     0.430779  \n",
       "min       2.720000     0.220000     8.000000     3.000000     0.000000  \n",
       "25%       3.110000     0.430000     9.500000     5.000000     0.000000  \n",
       "50%       3.210000     0.510000    10.300000     6.000000     0.000000  \n",
       "75%       3.320000     0.600000    11.300000     6.000000     0.000000  \n",
       "max       4.010000     2.000000    14.900000     9.000000     1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the statistical summary of the data set\n",
    "wine.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-great",
   "metadata": {},
   "source": [
    "Imagine we want to attempt to estimate the perceived quality of a wine using these attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comfortable-building",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    2836\n",
       "5    2138\n",
       "7    1079\n",
       "4     216\n",
       "8     193\n",
       "3      30\n",
       "9       5\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count each unique wine quality rating in the data set\n",
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nutritional-flood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4898\n",
       "1    1599\n",
       "Name: red_wine, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the total of red wine / non-red wine in the data set\n",
    "wine['red_wine'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-cookie",
   "metadata": {},
   "source": [
    "## üß† **Knowledge Check**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-confidence",
   "metadata": {},
   "source": [
    "> Why are we using \"quality\" as the dependent variable (target)? Would it make sense for another feature to be the target instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-gothic",
   "metadata": {},
   "source": [
    "## Running the Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-picture",
   "metadata": {},
   "source": [
    "First, we'll separate the data into our predictors (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "automated-toolbox",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>red_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  red_wine  \n",
       "0      9.4         1  \n",
       "1      9.8         1  \n",
       "2      9.8         1  \n",
       "3      9.8         1  \n",
       "4      9.4         1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the target and predictors for regression\n",
    "wine_preds = wine.drop('quality', axis=1)\n",
    "wine_target = wine['quality']\n",
    "\n",
    "# Check the predictors data frame\n",
    "wine_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-agenda",
   "metadata": {},
   "source": [
    "Now we can perform our (multiple) linear regression! Since we already used `statsmodels`, let's use that again to fit the model and then check the summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "arranged-bahrain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>red_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      const  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0       1.0            7.4              0.70         0.00             1.9   \n",
       "1       1.0            7.8              0.88         0.00             2.6   \n",
       "2       1.0            7.8              0.76         0.04             2.3   \n",
       "3       1.0           11.2              0.28         0.56             1.9   \n",
       "4       1.0            7.4              0.70         0.00             1.9   \n",
       "...     ...            ...               ...          ...             ...   \n",
       "6492    1.0            6.2              0.21         0.29             1.6   \n",
       "6493    1.0            6.6              0.32         0.36             8.0   \n",
       "6494    1.0            6.5              0.24         0.19             1.2   \n",
       "6495    1.0            5.5              0.29         0.30             1.1   \n",
       "6496    1.0            6.0              0.21         0.38             0.8   \n",
       "\n",
       "      chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0         0.076                 11.0                  34.0  0.99780  3.51   \n",
       "1         0.098                 25.0                  67.0  0.99680  3.20   \n",
       "2         0.092                 15.0                  54.0  0.99700  3.26   \n",
       "3         0.075                 17.0                  60.0  0.99800  3.16   \n",
       "4         0.076                 11.0                  34.0  0.99780  3.51   \n",
       "...         ...                  ...                   ...      ...   ...   \n",
       "6492      0.039                 24.0                  92.0  0.99114  3.27   \n",
       "6493      0.047                 57.0                 168.0  0.99490  3.15   \n",
       "6494      0.041                 30.0                 111.0  0.99254  2.99   \n",
       "6495      0.022                 20.0                 110.0  0.98869  3.34   \n",
       "6496      0.020                 22.0                  98.0  0.98941  3.26   \n",
       "\n",
       "      sulphates  alcohol  red_wine  \n",
       "0          0.56      9.4         1  \n",
       "1          0.68      9.8         1  \n",
       "2          0.65      9.8         1  \n",
       "3          0.58      9.8         1  \n",
       "4          0.56      9.4         1  \n",
       "...         ...      ...       ...  \n",
       "6492       0.50     11.2         0  \n",
       "6493       0.46      9.6         0  \n",
       "6494       0.46      9.4         0  \n",
       "6495       0.38     12.8         0  \n",
       "6496       0.32     11.8         0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use sm.add_constant() to add constant term/y-intercept\n",
    "predictors = sm.add_constant(wine_preds)\n",
    "\n",
    "# Check if the constant column has been added to the data frame\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "outside-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OLS model and fit the data\n",
    "model = sm.OLS(wine_target, predictors).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-database",
   "metadata": {},
   "source": [
    "> Alright! So we fitted our model! Take a look at the summary and look if you can understand the different parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "actual-cheat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>quality</td>     <th>  R-squared:         </th> <td>   0.297</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.295</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   227.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 04 Jul 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:48:39</td>     <th>  Log-Likelihood:    </th> <td> -7195.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6497</td>      <th>  AIC:               </th> <td>1.442e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6484</td>      <th>  BIC:               </th> <td>1.450e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>  104.3904</td> <td>   14.105</td> <td>    7.401</td> <td> 0.000</td> <td>   76.741</td> <td>  132.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fixed acidity</th>        <td>    0.0851</td> <td>    0.016</td> <td>    5.396</td> <td> 0.000</td> <td>    0.054</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -1.4924</td> <td>    0.081</td> <td>  -18.345</td> <td> 0.000</td> <td>   -1.652</td> <td>   -1.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citric acid</th>          <td>   -0.0626</td> <td>    0.080</td> <td>   -0.786</td> <td> 0.432</td> <td>   -0.219</td> <td>    0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.0624</td> <td>    0.006</td> <td>   10.522</td> <td> 0.000</td> <td>    0.051</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -0.7573</td> <td>    0.334</td> <td>   -2.264</td> <td> 0.024</td> <td>   -1.413</td> <td>   -0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free sulfur dioxide</th>  <td>    0.0049</td> <td>    0.001</td> <td>    6.443</td> <td> 0.000</td> <td>    0.003</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0014</td> <td>    0.000</td> <td>   -4.333</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>              <td> -103.9096</td> <td>   14.336</td> <td>   -7.248</td> <td> 0.000</td> <td> -132.013</td> <td>  -75.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>                   <td>    0.4988</td> <td>    0.091</td> <td>    5.506</td> <td> 0.000</td> <td>    0.321</td> <td>    0.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    0.7217</td> <td>    0.076</td> <td>    9.466</td> <td> 0.000</td> <td>    0.572</td> <td>    0.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.2227</td> <td>    0.018</td> <td>   12.320</td> <td> 0.000</td> <td>    0.187</td> <td>    0.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>red_wine</th>             <td>    0.3613</td> <td>    0.057</td> <td>    6.367</td> <td> 0.000</td> <td>    0.250</td> <td>    0.473</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>140.992</td> <th>  Durbin-Watson:     </th> <td>   1.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 313.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.016</td>  <th>  Prob(JB):          </th> <td>6.59e-69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.077</td>  <th>  Cond. No.          </th> <td>2.96e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.96e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                quality   R-squared:                       0.297\n",
       "Model:                            OLS   Adj. R-squared:                  0.295\n",
       "Method:                 Least Squares   F-statistic:                     227.8\n",
       "Date:                Sun, 04 Jul 2021   Prob (F-statistic):               0.00\n",
       "Time:                        13:48:39   Log-Likelihood:                -7195.2\n",
       "No. Observations:                6497   AIC:                         1.442e+04\n",
       "Df Residuals:                    6484   BIC:                         1.450e+04\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                  104.3904     14.105      7.401      0.000      76.741     132.040\n",
       "fixed acidity            0.0851      0.016      5.396      0.000       0.054       0.116\n",
       "volatile acidity        -1.4924      0.081    -18.345      0.000      -1.652      -1.333\n",
       "citric acid             -0.0626      0.080     -0.786      0.432      -0.219       0.094\n",
       "residual sugar           0.0624      0.006     10.522      0.000       0.051       0.074\n",
       "chlorides               -0.7573      0.334     -2.264      0.024      -1.413      -0.102\n",
       "free sulfur dioxide      0.0049      0.001      6.443      0.000       0.003       0.006\n",
       "total sulfur dioxide    -0.0014      0.000     -4.333      0.000      -0.002      -0.001\n",
       "density               -103.9096     14.336     -7.248      0.000    -132.013     -75.806\n",
       "pH                       0.4988      0.091      5.506      0.000       0.321       0.676\n",
       "sulphates                0.7217      0.076      9.466      0.000       0.572       0.871\n",
       "alcohol                  0.2227      0.018     12.320      0.000       0.187       0.258\n",
       "red_wine                 0.3613      0.057      6.367      0.000       0.250       0.473\n",
       "==============================================================================\n",
       "Omnibus:                      140.992   Durbin-Watson:                   1.648\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              313.985\n",
       "Skew:                           0.016   Prob(JB):                     6.59e-69\n",
       "Kurtosis:                       4.077   Cond. No.                     2.96e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.96e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the model summary table\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-covering",
   "metadata": {},
   "source": [
    "# Scaling - The Missing & Helpful Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-celebration",
   "metadata": {},
   "source": [
    "When you looked at the summary after we did the linear regression, you might have noticed something interesting.\n",
    "\n",
    "Observing the coefficients, you might notice there are two relatively large coefficients and nearly rest are less than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-breed",
   "metadata": {},
   "source": [
    "## What's Going on Here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-andrew",
   "metadata": {},
   "source": [
    "In a word, it's useful to have all of our variables be on the same scale, so that the resulting coefficients are easier to interpret. If the scales of the variables are very different one from another, then some of the coefficients may end up on very large or very tiny scales.\n",
    "\n",
    "This happens since the coefficients will effectively attempt to \"shrink\" or \"expand\" the features before factoring their importance to the model.\n",
    "\n",
    "![](img/shrinkinator.jpeg)\n",
    "\n",
    "This can make it more difficult for interpretation and identifying coefficients with the most \"effect\" on the prediction.\n",
    "\n",
    "For more on this, see [this post](https://stats.stackexchange.com/questions/32649/some-of-my-predictors-are-on-very-different-scales-do-i-need-to-transform-them)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-course",
   "metadata": {},
   "source": [
    "## A Solution: Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-gardening",
   "metadata": {},
   "source": [
    "One solution is to *scale* our features. There are a few ways to do this but we'll focus on **standard scaling**.\n",
    "\n",
    "When we do **standard scaling**, we're really scaling it to be the features' respective $z$-scores.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "- This tends to make values relatively small (mean value is at $0$ and one standard deviation $\\sigma$ from the mean is $1$).\n",
    "- Easier interpretation: larger coefficients tend to be more influential\n",
    "\n",
    "Next time, let's *scale* our columns as $z$-scores first. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-stationery",
   "metadata": {},
   "source": [
    "##  Redoing with Standard Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-eclipse",
   "metadata": {},
   "source": [
    "Let's try standard scaling the model with our wine dataset now.\n",
    "\n",
    "*Z*-Score Formula:\n",
    "\n",
    "$$z = \\frac{x - \\bar{x}}{sd(x)}$$\n",
    "\n",
    "where \n",
    "\n",
    "- $x$ is the actual value of $x$\n",
    "- $\\bar{x}$ is the average of $x$\n",
    "- $sd(x)$ is the sample standard deviation of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "whole-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are scaling all colmuns using the z-scores formula\n",
    "wine_preds_scaled = (wine_preds - np.mean(wine_preds)) / np.std(wine_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abroad-animal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>red_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "      <td>6.497000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.014577e-14</td>\n",
       "      <td>-2.676336e-14</td>\n",
       "      <td>4.830012e-14</td>\n",
       "      <td>-2.203392e-15</td>\n",
       "      <td>1.208747e-14</td>\n",
       "      <td>1.714865e-15</td>\n",
       "      <td>-1.003020e-15</td>\n",
       "      <td>2.254710e-12</td>\n",
       "      <td>-3.333153e-14</td>\n",
       "      <td>-5.293322e-15</td>\n",
       "      <td>-1.200326e-14</td>\n",
       "      <td>1.064102e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "      <td>1.000077e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.634589e+00</td>\n",
       "      <td>-1.577330e+00</td>\n",
       "      <td>-2.192833e+00</td>\n",
       "      <td>-1.018034e+00</td>\n",
       "      <td>-1.342639e+00</td>\n",
       "      <td>-1.663583e+00</td>\n",
       "      <td>-1.941780e+00</td>\n",
       "      <td>-2.530192e+00</td>\n",
       "      <td>-3.100615e+00</td>\n",
       "      <td>-2.091935e+00</td>\n",
       "      <td>-2.089350e+00</td>\n",
       "      <td>-5.713666e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.289329e-01</td>\n",
       "      <td>-6.661613e-01</td>\n",
       "      <td>-4.723335e-01</td>\n",
       "      <td>-7.657978e-01</td>\n",
       "      <td>-5.147986e-01</td>\n",
       "      <td>-7.620742e-01</td>\n",
       "      <td>-6.855323e-01</td>\n",
       "      <td>-7.859527e-01</td>\n",
       "      <td>-6.748622e-01</td>\n",
       "      <td>-6.805919e-01</td>\n",
       "      <td>-8.316152e-01</td>\n",
       "      <td>-5.713666e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.660892e-01</td>\n",
       "      <td>-3.016939e-01</td>\n",
       "      <td>-5.941375e-02</td>\n",
       "      <td>-5.135612e-01</td>\n",
       "      <td>-2.578826e-01</td>\n",
       "      <td>-8.594301e-02</td>\n",
       "      <td>3.990667e-02</td>\n",
       "      <td>6.448888e-02</td>\n",
       "      <td>-5.287424e-02</td>\n",
       "      <td>-1.429373e-01</td>\n",
       "      <td>-1.608231e-01</td>\n",
       "      <td>-5.713666e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.738951e-01</td>\n",
       "      <td>3.664962e-01</td>\n",
       "      <td>4.911459e-01</td>\n",
       "      <td>5.584445e-01</td>\n",
       "      <td>2.559494e-01</td>\n",
       "      <td>5.901882e-01</td>\n",
       "      <td>7.122647e-01</td>\n",
       "      <td>7.648525e-01</td>\n",
       "      <td>6.313125e-01</td>\n",
       "      <td>4.619241e-01</td>\n",
       "      <td>6.776670e-01</td>\n",
       "      <td>-5.713666e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.699425e+00</td>\n",
       "      <td>7.534354e+00</td>\n",
       "      <td>9.231281e+00</td>\n",
       "      <td>1.268682e+01</td>\n",
       "      <td>1.584219e+01</td>\n",
       "      <td>1.456357e+01</td>\n",
       "      <td>5.737257e+00</td>\n",
       "      <td>1.476879e+01</td>\n",
       "      <td>4.923029e+00</td>\n",
       "      <td>9.870879e+00</td>\n",
       "      <td>3.696231e+00</td>\n",
       "      <td>1.750190e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity   citric acid  residual sugar  \\\n",
       "count   6.497000e+03      6.497000e+03  6.497000e+03    6.497000e+03   \n",
       "mean    1.014577e-14     -2.676336e-14  4.830012e-14   -2.203392e-15   \n",
       "std     1.000077e+00      1.000077e+00  1.000077e+00    1.000077e+00   \n",
       "min    -2.634589e+00     -1.577330e+00 -2.192833e+00   -1.018034e+00   \n",
       "25%    -6.289329e-01     -6.661613e-01 -4.723335e-01   -7.657978e-01   \n",
       "50%    -1.660892e-01     -3.016939e-01 -5.941375e-02   -5.135612e-01   \n",
       "75%     3.738951e-01      3.664962e-01  4.911459e-01    5.584445e-01   \n",
       "max     6.699425e+00      7.534354e+00  9.231281e+00    1.268682e+01   \n",
       "\n",
       "          chlorides  free sulfur dioxide  total sulfur dioxide       density  \\\n",
       "count  6.497000e+03         6.497000e+03          6.497000e+03  6.497000e+03   \n",
       "mean   1.208747e-14         1.714865e-15         -1.003020e-15  2.254710e-12   \n",
       "std    1.000077e+00         1.000077e+00          1.000077e+00  1.000077e+00   \n",
       "min   -1.342639e+00        -1.663583e+00         -1.941780e+00 -2.530192e+00   \n",
       "25%   -5.147986e-01        -7.620742e-01         -6.855323e-01 -7.859527e-01   \n",
       "50%   -2.578826e-01        -8.594301e-02          3.990667e-02  6.448888e-02   \n",
       "75%    2.559494e-01         5.901882e-01          7.122647e-01  7.648525e-01   \n",
       "max    1.584219e+01         1.456357e+01          5.737257e+00  1.476879e+01   \n",
       "\n",
       "                 pH     sulphates       alcohol      red_wine  \n",
       "count  6.497000e+03  6.497000e+03  6.497000e+03  6.497000e+03  \n",
       "mean  -3.333153e-14 -5.293322e-15 -1.200326e-14  1.064102e-14  \n",
       "std    1.000077e+00  1.000077e+00  1.000077e+00  1.000077e+00  \n",
       "min   -3.100615e+00 -2.091935e+00 -2.089350e+00 -5.713666e-01  \n",
       "25%   -6.748622e-01 -6.805919e-01 -8.316152e-01 -5.713666e-01  \n",
       "50%   -5.287424e-02 -1.429373e-01 -1.608231e-01 -5.713666e-01  \n",
       "75%    6.313125e-01  4.619241e-01  6.776670e-01 -5.713666e-01  \n",
       "max    4.923029e+00  9.870879e+00  3.696231e+00  1.750190e+00  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the statistial summary of the scaled data set\n",
    "wine_preds_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pressing-paper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>quality</td>     <th>  R-squared:         </th> <td>   0.297</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.295</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   227.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 04 Jul 2021</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:48:51</td>     <th>  Log-Likelihood:    </th> <td> -7195.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6497</td>      <th>  AIC:               </th> <td>1.442e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6484</td>      <th>  BIC:               </th> <td>1.450e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>    5.8184</td> <td>    0.009</td> <td>  639.726</td> <td> 0.000</td> <td>    5.801</td> <td>    5.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fixed acidity</th>        <td>    0.1103</td> <td>    0.020</td> <td>    5.396</td> <td> 0.000</td> <td>    0.070</td> <td>    0.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volatile acidity</th>     <td>   -0.2457</td> <td>    0.013</td> <td>  -18.345</td> <td> 0.000</td> <td>   -0.272</td> <td>   -0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citric acid</th>          <td>   -0.0091</td> <td>    0.012</td> <td>   -0.786</td> <td> 0.432</td> <td>   -0.032</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>residual sugar</th>       <td>    0.2970</td> <td>    0.028</td> <td>   10.522</td> <td> 0.000</td> <td>    0.242</td> <td>    0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>chlorides</th>            <td>   -0.0265</td> <td>    0.012</td> <td>   -2.264</td> <td> 0.024</td> <td>   -0.049</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>free sulfur dioxide</th>  <td>    0.0876</td> <td>    0.014</td> <td>    6.443</td> <td> 0.000</td> <td>    0.061</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total sulfur dioxide</th> <td>   -0.0793</td> <td>    0.018</td> <td>   -4.333</td> <td> 0.000</td> <td>   -0.115</td> <td>   -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>              <td>   -0.3116</td> <td>    0.043</td> <td>   -7.248</td> <td> 0.000</td> <td>   -0.396</td> <td>   -0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pH</th>                   <td>    0.0802</td> <td>    0.015</td> <td>    5.506</td> <td> 0.000</td> <td>    0.052</td> <td>    0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sulphates</th>            <td>    0.1074</td> <td>    0.011</td> <td>    9.466</td> <td> 0.000</td> <td>    0.085</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alcohol</th>              <td>    0.2656</td> <td>    0.022</td> <td>   12.320</td> <td> 0.000</td> <td>    0.223</td> <td>    0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>red_wine</th>             <td>    0.1556</td> <td>    0.024</td> <td>    6.367</td> <td> 0.000</td> <td>    0.108</td> <td>    0.204</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>140.992</td> <th>  Durbin-Watson:     </th> <td>   1.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 313.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.016</td>  <th>  Prob(JB):          </th> <td>6.59e-69</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.077</td>  <th>  Cond. No.          </th> <td>    12.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                quality   R-squared:                       0.297\n",
       "Model:                            OLS   Adj. R-squared:                  0.295\n",
       "Method:                 Least Squares   F-statistic:                     227.8\n",
       "Date:                Sun, 04 Jul 2021   Prob (F-statistic):               0.00\n",
       "Time:                        13:48:51   Log-Likelihood:                -7195.2\n",
       "No. Observations:                6497   AIC:                         1.442e+04\n",
       "Df Residuals:                    6484   BIC:                         1.450e+04\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                    5.8184      0.009    639.726      0.000       5.801       5.836\n",
       "fixed acidity            0.1103      0.020      5.396      0.000       0.070       0.150\n",
       "volatile acidity        -0.2457      0.013    -18.345      0.000      -0.272      -0.219\n",
       "citric acid             -0.0091      0.012     -0.786      0.432      -0.032       0.014\n",
       "residual sugar           0.2970      0.028     10.522      0.000       0.242       0.352\n",
       "chlorides               -0.0265      0.012     -2.264      0.024      -0.049      -0.004\n",
       "free sulfur dioxide      0.0876      0.014      6.443      0.000       0.061       0.114\n",
       "total sulfur dioxide    -0.0793      0.018     -4.333      0.000      -0.115      -0.043\n",
       "density                 -0.3116      0.043     -7.248      0.000      -0.396      -0.227\n",
       "pH                       0.0802      0.015      5.506      0.000       0.052       0.109\n",
       "sulphates                0.1074      0.011      9.466      0.000       0.085       0.130\n",
       "alcohol                  0.2656      0.022     12.320      0.000       0.223       0.308\n",
       "red_wine                 0.1556      0.024      6.367      0.000       0.108       0.204\n",
       "==============================================================================\n",
       "Omnibus:                      140.992   Durbin-Watson:                   1.648\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              313.985\n",
       "Skew:                           0.016   Prob(JB):                     6.59e-69\n",
       "Kurtosis:                       4.077   Cond. No.                         12.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's run the model with the standardized data\n",
    "predictors_scaled = sm.add_constant(wine_preds_scaled)\n",
    "model = sm.OLS(wine_target, predictors_scaled).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-holmes",
   "metadata": {},
   "source": [
    "> Check how well this model did with the one before scaling. Does it perform any differently?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-payment",
   "metadata": {},
   "source": [
    "Type *Markdown* and LateX: $\\alpha^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "broken-employment",
   "metadata": {},
   "source": [
    "## üß† **Knowledge Check**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-ridge",
   "metadata": {},
   "source": [
    "> After standard scaling, what would it mean when all the $x_i$ are all $0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-pocket",
   "metadata": {},
   "source": [
    "## üß† **Knowledge Check**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-feeding",
   "metadata": {},
   "source": [
    "### Follow-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-order",
   "metadata": {},
   "source": [
    "> What does this mean for the constant term $\\hat{\\beta}_0$? Could we check this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-maker",
   "metadata": {},
   "source": [
    "# Multiple Regression in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-thirty",
   "metadata": {},
   "source": [
    "It's great that we tried out multiple linear regression with `statsmodels`; now let's try it with `sklearn`!\n",
    "\n",
    "The Sklearn library provides us with a Linear Regression model that will fit a line to our data. Sklearn follows a consistent API where you define a model object, fit the model to the data, and then make predictions with the model.\n",
    "![sklearn](img/sklearn_api.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-effect",
   "metadata": {},
   "source": [
    "## Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a StandardScaler object to scale our data for us.\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-nomination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll apply it to our data by using the .fit() and .transform() methods.\n",
    "ss.fit(wine_preds)\n",
    "wine_preds_st_scaled = ss.transform(wine_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the scaling worked about the same as when we did it by hand\n",
    "np.allclose(wine_preds_st_scaled, wine_preds_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_preds_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the mean of the target 'wine quality'\n",
    "wine_target.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 5 scaled observations\n",
    "wine_preds_st_scaled[:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-scope",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-clothing",
   "metadata": {},
   "source": [
    "Now we can fit a `LinearRegression` object to our training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-cheese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OLS Regression object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the training data using the OLS regression object\n",
    "lr.fit(wine_preds_st_scaled, wine_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the coefficient values using the .coef_ attribute\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preceding-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the intercept coefficient\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the R^2 score of the model\n",
    "lr.score(wine_preds_st_scaled, wine_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the training data set to predict the target values\n",
    "y_hat = lr.predict(wine_preds_st_scaled)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-capacity",
   "metadata": {},
   "source": [
    "All that's left is to evaluate our model to see how well it did!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-thumbnail",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-balance",
   "metadata": {},
   "source": [
    "### Observing Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-tulsa",
   "metadata": {},
   "source": [
    "We can check the residuals like we would for a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predicted values array\n",
    "y_hat = lr.predict(wine_preds_st_scaled)\n",
    "\n",
    "# Calculate the residual (Actual - Predicted)\n",
    "resid = (wine_target - y_hat)\n",
    "\n",
    "# Display the residual across all predicted values\n",
    "plt.scatter(x=range(y_hat.shape[0]),y=resid, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-mixer",
   "metadata": {},
   "source": [
    "### Sklearn Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-munich",
   "metadata": {},
   "source": [
    "The metrics module in sklearn has a number of metrics that we can use to measure the accuracy of our model, including the $R^2$ score, the mean absolute error and the mean squared error. Note that the default 'score' on our model object is the $R^2$ score. Let's go back to our wine dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the R^2 of the model\n",
    "metrics.r2_score(wine_target, lr.predict(wine_preds_st_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-carroll",
   "metadata": {},
   "source": [
    "Let's make sure this metric is properly calibrated. If we put simply $\\bar{y}$ as our prediction, then we should get an $R^2$ score of *0*. And if we predict, say, $\\bar{y} + 1$, then we should get a *negative* $R^2$ score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculat the average target value\n",
    "avg_quality = np.mean(wine_target)\n",
    "\n",
    "# Calculate the total number of observations\n",
    "num = len(wine_target)\n",
    "\n",
    "# Check the R^2 with the average of the target values\n",
    "metrics.r2_score(wine_target, avg_quality * np.ones(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the R^2 with average of the target values + 1\n",
    "metrics.r2_score(wine_target, (avg_quality + 1) * np.ones(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the mean absolute error (MAE)\n",
    "metrics.mean_absolute_error(wine_target, lr.predict(wine_preds_st_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the mean squared error (MSE)\n",
    "metrics.mean_squared_error(wine_target, lr.predict(wine_preds_st_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-injection",
   "metadata": {},
   "source": [
    "**Practice with a Partner: (20 minutes)**\n",
    "\n",
    "We have a interesting data set that study our brain. In this exercise we are trying to use multiple features to predict brain **weight**.\n",
    "\n",
    "Source: R.J. Gladstone (1905). \"A Study of the Relations of the Brain to the Size of the Head\", Biometrika, Vol. 4, pp105-123\n",
    "\n",
    "Description: Brain weight (grams) and head size (cubic cm) for 237 adults classified by gender and age group.\n",
    "\n",
    "Variables/Columns:\n",
    "\n",
    "GENDER: Gender  Male or Female  \n",
    "AGE: Age Range  20-46 or 46+  \n",
    "SIZE: Head size ($cm^3$)  21-24  \n",
    "WEIGHT: Brain weight (grams)  29-32 \n",
    "\n",
    "**Objectives:**\n",
    "- Follow the standard workflow, such as checking the data type, cleaning the data, prepare data for regression model.\n",
    "- Create dummy variables for the categorical data using either Pandas ```pd.get_dummy()``` or sklearn ```OneHotEncoder()```.\n",
    "- Scale the data using sklearn ```standardScaler()```.\n",
    "- Fit the data in multiple linear regression and evaluate the results.\n",
    "- Evaluate the model using different metrics, $R^2$, MAE, MSE.\n",
    "\n",
    "Follow the instructions and complete a coding exercise with a partner in the class (in the random breakout room). Instructor will go into the rooms to help answering questions from students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "indonesian-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aboriginal-combination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>size</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>20-46</td>\n",
       "      <td>4512</td>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>20-46</td>\n",
       "      <td>3738</td>\n",
       "      <td>1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>20-46</td>\n",
       "      <td>4261</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>20-46</td>\n",
       "      <td>3777</td>\n",
       "      <td>1282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>20-46</td>\n",
       "      <td>4177</td>\n",
       "      <td>1590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender    age  size  weight\n",
       "0   Male  20-46  4512    1530\n",
       "1   Male  20-46  3738    1297\n",
       "2   Male  20-46  4261    1335\n",
       "3   Male  20-46  3777    1282\n",
       "4   Male  20-46  4177    1590"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file into a pandas DataFrame\n",
    "brain = pd.read_csv('data/brain_categorical.csv')\n",
    "brain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-freeware",
   "metadata": {},
   "source": [
    "Step 1: Checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "seasonal-start",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 237 entries, 0 to 236\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   gender  237 non-null    object\n",
      " 1   age     237 non-null    object\n",
      " 2   size    237 non-null    int64 \n",
      " 3   weight  237 non-null    int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 7.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Use the .info() method to check the data set\n",
    "brain.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-gossip",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "1. Do we have any missing data?\n",
    "2. What are the data type for each variable (column)?\n",
    "3. Do we need to clean the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "appreciated-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>237.000000</td>\n",
       "      <td>237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3633.991561</td>\n",
       "      <td>1282.873418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>365.261422</td>\n",
       "      <td>120.340446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2720.000000</td>\n",
       "      <td>955.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3389.000000</td>\n",
       "      <td>1207.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3614.000000</td>\n",
       "      <td>1280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3876.000000</td>\n",
       "      <td>1350.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4747.000000</td>\n",
       "      <td>1635.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              size       weight\n",
       "count   237.000000   237.000000\n",
       "mean   3633.991561  1282.873418\n",
       "std     365.261422   120.340446\n",
       "min    2720.000000   955.000000\n",
       "25%    3389.000000  1207.000000\n",
       "50%    3614.000000  1280.000000\n",
       "75%    3876.000000  1350.000000\n",
       "max    4747.000000  1635.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the .describe() method to print the statistical summary of the data set\n",
    "brain.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-phoenix",
   "metadata": {},
   "source": [
    "Question:\n",
    "\n",
    "1. Why are we see the statistical summary returning only two columns (size and weight)?\n",
    "\n",
    "Let's check the count of each category (level) in both categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "established-arcade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      134\n",
       "Female    103\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of male and female\n",
    "brain['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "foreign-leeds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46+      127\n",
       "20-46    110\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of different age groups\n",
    "brain['age'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-sending",
   "metadata": {},
   "source": [
    "Next, let's create the predictors and target dataframes.\n",
    "\n",
    "Example:\n",
    "\n",
    "``` Python\n",
    "# Create predictors dataframe\n",
    "predictors = data.drop('target_name', axis=1)\n",
    "\n",
    "# Create target dataframe\n",
    "target = data['target_name']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "considerable-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predictors and target dataframes\n",
    "predictors = brain.drop('weight', axis = 1)\n",
    "target = brain['weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-avenue",
   "metadata": {},
   "source": [
    "Now that we have studied the data set and knowing that there are two categorical variables (columns). We need to create dummy columns.\n",
    "\n",
    "Feel free to use either *Pandas* ```pd.get_dummies()``` or *sklearn* ```OneHotEncoder()``` for this task.\n",
    "\n",
    "Example:\n",
    "\n",
    "``` Python\n",
    "# Create dummy columns with Pandas function\n",
    "data_encoded = pd.get_dummies(data, drop_first = True)\n",
    "\n",
    "# Create dummy columns with sklearn OneHotEncoder\n",
    "ohe = OneHotEncoder(drop = 'first')\n",
    "data_trans = ohe.fit_transform(data['categorical_columns'])\n",
    "data_encoded = pd.DataFrame(data_trans.todense(), columns = ohe.get_feature_names())\n",
    "data_encoded.join(data['numerical_columns'])\n",
    "data_encoded\n",
    "```\n",
    "\n",
    "Note: *Remember when we are fitting / training the data with the OLS regression model, we need to exclude one level from each categorical variable as the reference level.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "flexible-treasurer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     size  gender_Male  age_46+\n",
      "0    4512            1        0\n",
      "1    3738            1        0\n",
      "2    4261            1        0\n",
      "3    3777            1        0\n",
      "4    4177            1        0\n",
      "..    ...          ...      ...\n",
      "232  3214            0        1\n",
      "233  3394            0        1\n",
      "234  3233            0        1\n",
      "235  3352            0        1\n",
      "236  3391            0        1\n",
      "\n",
      "[237 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create the categorical columns with Pandas DataFrame\n",
    "predictors_encoded = pd.get_dummies(predictors, drop_first = True)\n",
    "print(predictors_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "incoming-abraham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x0_Male  x1_46+  size\n",
      "0        1.0     0.0  4512\n",
      "1        1.0     0.0  3738\n",
      "2        1.0     0.0  4261\n",
      "3        1.0     0.0  3777\n",
      "4        1.0     0.0  4177\n",
      "..       ...     ...   ...\n",
      "232      0.0     1.0  3214\n",
      "233      0.0     1.0  3394\n",
      "234      0.0     1.0  3233\n",
      "235      0.0     1.0  3352\n",
      "236      0.0     1.0  3391\n",
      "\n",
      "[237 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create the categorical columns with sklearn OneHotEncoder (optional)\n",
    "ohe = OneHotEncoder(drop = 'first')\n",
    "predictors_trans = ohe.fit_transform(predictors[['gender', 'age']])\n",
    "predictors_encoded = pd.DataFrame(predictors_trans.todense(), columns = ohe.get_feature_names())\n",
    "predictors_encoded = predictors_encoded.join(predictors['size'])\n",
    "print(predictors_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-regression",
   "metadata": {},
   "source": [
    "Check the encoded predictors dataframe to make sure the dummy columns are created and the original columns are removed.\n",
    "\n",
    "Let's run the sklearn OLS with the encoded data and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OLS Regression object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the training data using the OLS regression object\n",
    "lr.fit(predictors_encoded, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the coefficient values using the .coef_ attribute\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "pharmaceutical-married",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the intercept coefficient\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-bankruptcy",
   "metadata": {},
   "source": [
    "If we look at the estimated coefficents, there are two relatively large coefficients (gender_male and age_46+) and a cofficient (size) less than 1. \n",
    "\n",
    "Remember, we can use the sklearn ```StandardScaler()``` to standardize the data, so the variables will be on the same scale.\n",
    "\n",
    "Example:\n",
    "\n",
    "``` Python\n",
    "# Create the StandardScaler object\n",
    "ss = StandardScaler()\n",
    "\n",
    "## Apply it to our data by using the .fit() and .transform() methods\n",
    "data_scaler = ss.fit(data)\n",
    "data_scaled = data_scaler.transform(data)\n",
    "```\n",
    "\n",
    "Note: *The StandardScaler is expecting a 2D array for input. If we are scaling our target variable, we need to reshape the dataframe using ```target.values.reshape(-1, 1)``` in the .fit() and .transfrom() functions.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "alike-syndicate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       male       46+      size\n",
      "0  0.876731 -1.074498  2.408868\n",
      "1  0.876731 -1.074498  0.285353\n",
      "2  0.876731 -1.074498  1.720235\n",
      "3  0.876731 -1.074498  0.392352\n",
      "4  0.876731 -1.074498  1.489776\n",
      "     weight\n",
      "0  2.057908\n",
      "1  0.117637\n",
      "2  0.434076\n",
      "3 -0.007273\n",
      "4  2.557549\n"
     ]
    }
   ],
   "source": [
    "# Create the StandardScaler object\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Apply it the predictors and target by using the .fit() and .transform() methods\n",
    "predictors_scaler = ss.fit(predictors_encoded)\n",
    "predictors_scaled = predictors_scaler.transform(predictors_encoded)\n",
    "\n",
    "target_scaler = ss.fit(target.values.reshape(-1, 1))\n",
    "target_scaled = target_scaler.transform(target.values.reshape(-1, 1))\n",
    "\n",
    "# Create the scaled dataframes\n",
    "predictors_scaled = pd.DataFrame(predictors_scaled, columns = ['male', '46+', 'size'])\n",
    "target_scaled = pd.DataFrame(target_scaled, columns = ['weight'])\n",
    "\n",
    "# Print the scaled predictors and target\n",
    "print(predictors_scaled.head())\n",
    "print(target_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-manual",
   "metadata": {},
   "source": [
    "Let's run the sklearn OLS regrssion on the scaled data again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "twelve-panel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the OLS Regression object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the training data using the OLS regression object\n",
    "lr.fit(predictors_scaled, target_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "surface-creator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09305631, -0.09953969,  0.74123982]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the coefficient values using the .coef_ attribute\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "acoustic-healthcare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.89583504e-16])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the intercept coefficient\n",
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "hollywood-singer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the scaling effect\n",
    "fig1 = plt.figure(figsize=(12, 6))\n",
    "axes1 = fig1.add_subplot(1, 2, 1)\n",
    "axes2 = fig1.add_subplot(1, 2, 2)\n",
    "\n",
    "axes1.set_title(\"Original Data\")\n",
    "axes2.set_title(\"Scaled Data\")\n",
    "\n",
    "maxx = predictors_encoded['size'].max()\n",
    "maxy = target.max()\n",
    "axes1.set_xlim(-maxx + 1, maxx + 1)\n",
    "axes1.set_ylim(-maxy + 1, maxy + 1)\n",
    "\n",
    "axes2.set_xlim(-2, 2)\n",
    "axes2.set_ylim(-2, 2)\n",
    "\n",
    "def set_axes(ax):\n",
    "    ax.spines['left'].set_position('center')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['bottom'].set_position('center')\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    \n",
    "set_axes(axes1)\n",
    "set_axes(axes2)\n",
    "\n",
    "axes1.scatter(predictors_encoded['size'], target)\n",
    "axes2.scatter(predictors_scaled['size'], target_scaled['weight'])\n",
    "plt.savefig('img/standard_scaling.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-liver",
   "metadata": {},
   "source": [
    "Let's evaluate the model with different metrics, such as $R^2$, MAE, and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "outdoor-nightmare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6528346387526653"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the R^2 score of the model\n",
    "lr.score(predictors_scaled, target_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "exposed-november",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46094178757136256"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the mean absolute error (MAE)\n",
    "metrics.mean_absolute_error(target_scaled, lr.predict(predictors_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eastern-concentration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34716536124733455"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the mean squared error (MSE)\n",
    "metrics.mean_squared_error(target_scaled, lr.predict(predictors_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-element",
   "metadata": {},
   "source": [
    "**Final Challenge:**\n",
    "\n",
    "Let's use statsmodel OLS regression to confirm our results from the previous exercise. Run two OLS regression, one with the encoded data and one with the scaled data.\n",
    "\n",
    "Check the coefficient and $R^2$ values. They should be the same as the sklearn OLS regression models.  If they are not, something is wrong!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "synthetic-function",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>weight</td>      <th>  R-squared:         </th> <td>   0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   146.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 04 Jul 2021</td> <th>  Prob (F-statistic):</th> <td>2.94e-53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:49:52</td>     <th>  Log-Likelihood:    </th> <td> -1345.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   237</td>      <th>  AIC:               </th> <td>   2699.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   233</td>      <th>  BIC:               </th> <td>   2713.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>  395.5079</td> <td>   52.999</td> <td>    7.463</td> <td> 0.000</td> <td>  291.090</td> <td>  499.926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x0_Male</th> <td>   22.5433</td> <td>   11.058</td> <td>    2.039</td> <td> 0.043</td> <td>    0.757</td> <td>   44.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1_46+</th>  <td>  -23.9684</td> <td>    9.481</td> <td>   -2.528</td> <td> 0.012</td> <td>  -42.647</td> <td>   -5.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>size</th>    <td>    0.2442</td> <td>    0.015</td> <td>   16.212</td> <td> 0.000</td> <td>    0.215</td> <td>    0.274</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.989</td> <th>  Durbin-Watson:     </th> <td>   1.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.018</td> <th>  Jarque-Bera (JB):  </th> <td>   8.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.357</td> <th>  Prob(JB):          </th> <td>  0.0161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.571</td> <th>  Cond. No.          </th> <td>4.20e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.2e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 weight   R-squared:                       0.653\n",
       "Model:                            OLS   Adj. R-squared:                  0.648\n",
       "Method:                 Least Squares   F-statistic:                     146.0\n",
       "Date:                Sun, 04 Jul 2021   Prob (F-statistic):           2.94e-53\n",
       "Time:                        21:49:52   Log-Likelihood:                -1345.7\n",
       "No. Observations:                 237   AIC:                             2699.\n",
       "Df Residuals:                     233   BIC:                             2713.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        395.5079     52.999      7.463      0.000     291.090     499.926\n",
       "x0_Male       22.5433     11.058      2.039      0.043       0.757      44.329\n",
       "x1_46+       -23.9684      9.481     -2.528      0.012     -42.647      -5.290\n",
       "size           0.2442      0.015     16.212      0.000       0.215       0.274\n",
       "==============================================================================\n",
       "Omnibus:                        7.989   Durbin-Watson:                   1.922\n",
       "Prob(Omnibus):                  0.018   Jarque-Bera (JB):                8.255\n",
       "Skew:                           0.357   Prob(JB):                       0.0161\n",
       "Kurtosis:                       3.571   Cond. No.                     4.20e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.2e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the OLS model and fit the encoded data\n",
    "model = sm.OLS(target, sm.add_constant(predictors_encoded)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "pleased-institute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>weight</td>      <th>  R-squared:         </th> <td>   0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   146.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 04 Jul 2021</td> <th>  Prob (F-statistic):</th> <td>2.94e-53</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:49:53</td>     <th>  Log-Likelihood:    </th> <td> -210.92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   237</td>      <th>  AIC:               </th> <td>   429.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   233</td>      <th>  BIC:               </th> <td>   443.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-1.388e-17</td> <td>    0.039</td> <td> -3.6e-16</td> <td> 1.000</td> <td>   -0.076</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>male</th>  <td>    0.0931</td> <td>    0.046</td> <td>    2.039</td> <td> 0.043</td> <td>    0.003</td> <td>    0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>46+</th>   <td>   -0.0995</td> <td>    0.039</td> <td>   -2.528</td> <td> 0.012</td> <td>   -0.177</td> <td>   -0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>size</th>  <td>    0.7412</td> <td>    0.046</td> <td>   16.212</td> <td> 0.000</td> <td>    0.651</td> <td>    0.831</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.989</td> <th>  Durbin-Watson:     </th> <td>   1.922</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.018</td> <th>  Jarque-Bera (JB):  </th> <td>   8.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.357</td> <th>  Prob(JB):          </th> <td>  0.0161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.571</td> <th>  Cond. No.          </th> <td>    1.83</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 weight   R-squared:                       0.653\n",
       "Model:                            OLS   Adj. R-squared:                  0.648\n",
       "Method:                 Least Squares   F-statistic:                     146.0\n",
       "Date:                Sun, 04 Jul 2021   Prob (F-statistic):           2.94e-53\n",
       "Time:                        21:49:53   Log-Likelihood:                -210.92\n",
       "No. Observations:                 237   AIC:                             429.8\n",
       "Df Residuals:                     233   BIC:                             443.7\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -1.388e-17      0.039   -3.6e-16      1.000      -0.076       0.076\n",
       "male           0.0931      0.046      2.039      0.043       0.003       0.183\n",
       "46+           -0.0995      0.039     -2.528      0.012      -0.177      -0.022\n",
       "size           0.7412      0.046     16.212      0.000       0.651       0.831\n",
       "==============================================================================\n",
       "Omnibus:                        7.989   Durbin-Watson:                   1.922\n",
       "Prob(Omnibus):                  0.018   Jarque-Bera (JB):                8.255\n",
       "Skew:                           0.357   Prob(JB):                       0.0161\n",
       "Kurtosis:                       3.571   Cond. No.                         1.83\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the OLS model and fit the scaled data\n",
    "model = sm.OLS(target_scaled, sm.add_constant(predictors_scaled)).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-elite",
   "metadata": {},
   "source": [
    "# Level Up: Deeper Evaluation of Wine Data Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-medium",
   "metadata": {},
   "source": [
    "One thing we could have investigated from our [model on the Wine Data](#Multiple-Regression-in-Scikit-Learn) is how our predictions $\\hat{y}$ match with the actual target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the predicted wine quality\n",
    "sns.histplot(y_hat,kde=True,fill=False,stat='density',color='red')\n",
    "sns.histplot(wine_target,discrete=True,stat='density')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-expense",
   "metadata": {},
   "source": [
    "So there's a slight issue with our model; the linear regression believes the target values are on a continuum. We know that's not true from the data. \n",
    "\n",
    "An easy fix is to round the target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding the target values\n",
    "y_hat_rounded = np.round(y_hat)\n",
    "np.unique(y_hat_rounded, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-complaint",
   "metadata": {},
   "source": [
    "Plotting the distribution is a lot more meaningful if we require targets to be integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the predicted rounded values\n",
    "sns.histplot(np.round(y_hat),fill=False,discrete=True,stat='density',color='red')\n",
    "sns.histplot(wine_target,discrete=True,alpha=0.3,stat='density')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-executive",
   "metadata": {},
   "source": [
    "Note that our $R^2$ metric will be worse. This makes sense since we found a \"line of best fit\" that predicts continuous values. \n",
    "\n",
    "If the better option was _integer_ predictions, it would have predicted that instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the R^2 with the rounded values\n",
    "metrics.r2_score(wine_target, y_hat_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-harvard",
   "metadata": {},
   "source": [
    "You must decide yourself if this is worth doing or if a different model makes more sense (we'll see more models in future lectures)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-letter",
   "metadata": {},
   "source": [
    "# Level Up: Regression with Categorical Features with the Comma Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the column names of the comma data set\n",
    "comma_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll try to predict the first column of df: the extent to which\n",
    "# the person accepts the sentence\n",
    "# without the Oxford comma as more grammatically correct.\n",
    "\n",
    "comma_target = comma_df['x0_It\\'s important for a person to be honest, kind, and loyal.']\n",
    "\n",
    "comma_predictors = comma_df[['x8_30-44',\n",
    "       'x8_45-60', 'x8_> 60', 'x9_$100,000 - $149,999',\n",
    "       'x9_$150,000+', 'x9_$25,000 - $49,999', 'x9_$50,000 - $99,999']]\n",
    "\n",
    "comma_lr = LinearRegression()\n",
    "\n",
    "comma_lr.fit(comma_predictors, comma_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 of the model\n",
    "comma_lr.score(comma_predictors, comma_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE of the model prediction\n",
    "metrics.mean_squared_error(wine_target, y_hat_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimated coefficients\n",
    "comma_lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between x0 and other predictors\n",
    "comma_df.corr()['x0_It\\'s important for a person to be honest, kind, and loyal.']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-dealing",
   "metadata": {},
   "source": [
    "For more on the interpretation of regression coefficients for categorical variables, see [Erin's repo](https://github.com/hoffm386/coefficients-of-dropped-categorical-variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-parish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
